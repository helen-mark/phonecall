import os
import json
import time
import shutil
import pandas as pd
from datetime import datetime
from pathlib import Path
import subprocess
from preprocess_calls_full import AudioProcessor
from assign_tags_from_fixed_list import JsonFileTaggingAgent
from typing import Union
#from llama_cpp import Llama


class SmartAudioProcessor:

    def __init__(self, model, node_url, drive_audio_path, output_csv_path,
                 total_space_gb=80, batch_size_gb=2):

        my_tags = [
            "–Ω–∏–∑–∫–æ–µ_–∫–∞—á–µ—Å—Ç–≤–æ_—Å—Ç–∏—Ä–∫–∏_–∏–ª–∏_—á–∏—Å—Ç–∫–∏",
            "–Ω–µ_–∑–∞–º–µ–Ω–∏–ª–∏_–∫–æ–≤—Ä—ã_–≤–æ–≤—Ä–µ–º—è",
            "–∫–ª–∏–µ–Ω—Ç_—Ö–æ—á–µ—Ç_–¥–æ–±–∞–≤–∏—Ç—å_–∫–æ–≤—Ä—ã",
            "–∫–ª–∏–µ–Ω—Ç_—Ö–æ—á–µ—Ç_–º–µ–Ω—å—à–µ_–∫–æ–≤—Ä–æ–≤",
            "–ø–æ–≥–∞—à–µ–Ω–∏–µ_–¥–æ–ª–≥–∞",
            "—Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ_–¥–æ–≥–æ–≤–æ—Ä–∞",
            "–≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ_—É—Å–ª—É–≥",
            "–¥–æ–ª–≥–æ_–Ω–µ—Ç_–æ—Ç–≤–µ—Ç–∞_–Ω–∞_–∑–∞—è–≤–∫—É",
            "–ª–∏—à–Ω—è—è_–¥–æ—Å—Ç–∞–≤–∫–∞",
            "–¥–æ—Å—Ç–∞–≤–∏–ª–∏_–Ω–µ_—Ç–µ_–∫–æ–≤—Ä—ã",
            "–Ω–µ_–≤—ã—Å—Ç–∞–≤–ª–µ–Ω_–≤–æ–≤—Ä–µ–º—è_—Å—á–µ—Ç",
            "–Ω–µ–≤–µ—Ä–Ω–∞—è_—Å—É–º–º–∞_–≤_—Å—á–µ—Ç–µ",
            "–∫–æ–≤–µ—Ä_–∑–∞–±—Ä–∞–ª–∏_–±–µ–∑_–ø—Ä–∏—á–∏–Ω—ã",
            "–∑–∞–±—Ä–∞–ª–∏_–Ω–µ_—Ç–æ—Ç_–∫–æ–≤–µ—Ä",
            "–º–µ–Ω–µ–¥–∂–µ—Ä_–Ω–∞–≥—Ä—É–±–∏–ª_–∫–ª–∏–µ–Ω—Ç—É",
            "–Ω–µ–æ–ø—Ä–∞–≤–¥–∞–Ω–Ω–æ_–≤—ã—Å–æ–∫–∏–µ_—Ü–µ–Ω—ã",
            "–Ω–µ–æ–ø—Ä–∞–≤–¥–∞–Ω–Ω—ã–π_—Ä–æ—Å—Ç_—Ü–µ–Ω",
            "–Ω–æ–≤—ã–π_–∫–ª–∏–µ–Ω—Ç_–∑–∞–∫–ª—é—á–µ–Ω–∏–µ_–¥–æ–≥–æ–≤–æ—Ä–∞",
            "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è_–∏–ª–∏_—É—Ç–æ—á–Ω–µ–Ω–∏–µ_–¥–µ—Ç–∞–ª–µ–π",
            "–ø–æ–º–µ–Ω—è—Ç—å_—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏",
            "–º–µ–Ω–µ–¥–∂–µ—Ä_–æ–±–µ—â–∞–ª_–Ω–æ_–Ω–µ_—Å–≤—è–∑–∞–ª—Å—è_—Å_–∫–ª–∏–µ–Ω—Ç–æ–º",
            "–∫–ª–∏–µ–Ω—Ç_—É—Ö–æ–¥–∏—Ç_–∫_–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º",
            "–ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å_—É—Å–ª—É–≥–∏",
            "–æ—à–∏–±–∫–∞_–≤_–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö"
        ]
        self.drive_audio_path = drive_audio_path
        self.output_csv_path = output_csv_path
        self.total_space = total_space_gb
        self.batch_size = batch_size_gb

        self.ap = AudioProcessor(model_size='large')

        self.tagger = JsonFileTaggingAgent(
            model=model,
            node_url=node_url,
            tags_list=my_tags
        )

        self.local_temp_dir = "/content/temp_audio"
        self.local_whisper_dir = "/content/whisper_output"
        self.local_batch_dir = "/content/current_batch"

        # Create local dirs:
        for dir_path in [self.local_temp_dir, self.local_whisper_dir, self.local_batch_dir]:
            os.makedirs(dir_path, exist_ok=True)

        self.processed_files_log = "/content/drive/MyDrive/MCP_Call_Analytics/processed_files.json"

        print(f" Initializing SmartAudioProcessor")
        print(f" Audiofiles: {drive_audio_path}")
        print(f" Batch limit! : {batch_size_gb} GB")
        print(f" Total space: {total_space_gb} GB")

    # ========== Main method ==========

    def process_large_dataset(self):

        print("=" * 60)
        print("Start processing large dataset")
        print("=" * 60)

        # 1. Only get filenames without loading the files
        all_files = self._list_files_without_download()
        if not all_files:
            print("No files for processing")
            return []

        total_files = len(all_files)
        total_gb = self._estimate_total_size_gb(all_files)

        print(f"Total files: {total_files:,}")
        print(f"Total volume: {total_gb:.1f} GB")
        print(f"Batch size: {self.batch_size} GB")
        print(f"N bathces: {int(total_gb / self.batch_size) + 1}")

        # 2. Which files are already processed?
        processed = self._load_processed_list()
        to_process = [f for f in all_files if f not in processed]

        print(f"\n Processing status:")
        print(f" Already processed: {len(processed):,} files")
        print(f" To process: {len(to_process):,} files")
        print(f" Progress: {len(processed) / total_files * 100:.1f}%")

        if not to_process:
            print("\n All files are processed!")
        return []

        # 3. Process bathces
        batches = self._create_batches(to_process)
        print(f"\nüì¶ –°–æ–∑–¥–∞–Ω–æ {len(batches)} –±–∞—Ç—á–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        all_results = []
        start_time = time.time()

        for batch_num, batch_files in enumerate(batches, 1):
            batch_start = time.time()

            print(f"\n{'=' * 50}")
            print(f"‚ö° BATCH {batch_num}/{len(batches)}")
            print(f"{'=' * 50}")

            batch_size_gb = sum(self._get_file_size_gb(f) for f in batch_files)
            print(f" Files per batch: {len(batch_files)}")
            print(f" Batch size: {batch_size_gb:.2f} GB")

            # Process batch
            try:
                batch_results = self._process_batch(batch_files, batch_num)

                if batch_results:
                    all_results.extend(batch_results)
                    self._append_to_main_csv(batch_results)
                    self._update_processed_list(batch_files)

                batch_time = time.time() - batch_start
                avg_time_per_file = batch_time / len(batch_files) if batch_files else 0

                print(f"\n Batch {batch_num} processed in {batch_time:.1f} sec")
                print(f" Avg time per batch: {avg_time_per_file:.1f} sec")

                remaining_batches = len(batches) - batch_num
                if remaining_batches > 0:
                    estimated_remaining = remaining_batches * (time.time() - start_time) / batch_num
                    print(f" Time left: ~{estimated_remaining / 60:.1f} min")

            except Exception as e:
                print(f" Batch processing error {batch_num}: {e}")
                import traceback
                traceback.print_exc()

                continue

        # 5. Check and duplicates removal
        self._remove_duplicates_from_csv()

        total_time = time.time() - start_time
        print(f"\n{'=' * 60}")
        print(f" Processing finished!")
        print(f"{'=' * 60}")
        print(f" Processed: {len(all_results):,}")
        print(f" Total time: {total_time / 60:.1f} –º–∏–Ω")
        print(f" Speed: {len(all_results) / total_time * 60:.1f} —Ñ–∞–π–ª–æ–≤/–º–∏–Ω")
        print(f" Results saved to: {self.output_csv_path}")

        return all_results

    def _append_to_main_csv(self, batch_results):
        # uppend intermediary results
        if not batch_results:
            print("No results to save")
            return

        df_batch = pd.DataFrame(batch_results)

        if os.path.exists(self.output_csv_path):
            try:
                df_existing = pd.read_csv(self.output_csv_path)
                df_combined = pd.concat([df_existing, df_batch], ignore_index=True)
                df_combined.to_csv(self.output_csv_path, index=False, encoding='utf-8')

                print(f" Uppended {len(batch_results)} entries to {self.output_csv_path}")
                print(f" Now have total: {len(df_combined)} entries")

            except Exception as e:
                print(f"Error uppending an entrty: {e}")
                # Try save as new file
                df_batch.to_csv(self.output_csv_path, index=False, encoding='utf-8')
                print(f"Created new file with {len(batch_results)} entries")
        else:
            # No existing file. Create new file.
            df_batch.to_csv(self.output_csv_path, index=False, encoding='utf-8')
            print(f"Created new file {self.output_csv_path} with {len(batch_results)} entries")

    def _remove_duplicates_from_csv(self):
        if not os.path.exists(self.output_csv_path):
            return

        try:
            df = pd.read_csv(self.output_csv_path)

            if 'source_audio' in df.columns:
                duplicates = df.duplicated(subset=['source_audio'], keep='last').sum()

                if duplicates > 0:
                    print(f"üîç –ù–∞–π–¥–µ–Ω–æ {duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, —É–¥–∞–ª—è—é...")

                    df_clean = df.drop_duplicates(subset=['source_audio'], keep='last')
                    df_clean.to_csv(self.output_csv_path, index=False, encoding='utf-8')

                    print(f"üßπ –£–¥–∞–ª–µ–Ω–æ {duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
                    print(f"üìä –û—Å—Ç–∞–ª–æ—Å—å {len(df_clean)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
            else:
                print("‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∞ 'source_audio' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ CSV")

        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")

    def _load_processed_list(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        processed_files = set()

        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π CSV —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        if os.path.exists(self.output_csv_path):
            try:
                df = pd.read_csv(self.output_csv_path)
                if 'source_audio' in df.columns:
                    csv_processed = set(df['source_audio'].dropna().unique())
                    processed_files.update(csv_processed)
                    print(f"üìä –ò–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ CSV –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(csv_processed)} —Ñ–∞–π–ª–æ–≤")
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ CSV: {e}")

        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö (–¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏)
        # if os.path.exists(self.processed_files_log):
        #     try:
        #         with open(self.processed_files_log, 'r') as f:
        #             data = json.load(f)
        #             if isinstance(data, list):
        #                 log_processed = set(data)
        #                 processed_files.update(log_processed)
        #                 print(f"üìñ –ò–∑ –ª–æ–≥–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(log_processed)} —Ñ–∞–π–ª–æ–≤")
        #     except Exception as e:
        #         print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–æ–≥–∞: {e}")

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –ø–æ–ª–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        full_paths_processed = set()
        for filename in processed_files:
            full_path = os.path.join(self.drive_audio_path, filename)
            full_paths_processed.add(full_path)

        return full_paths_processed

    def _update_processed_list(self, processed_files):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫ –∏–∑ –ª–æ–≥–∞
            current_processed = []
            if os.path.exists(self.processed_files_log):
                with open(self.processed_files_log, 'r') as f:
                    current_processed = json.load(f)

            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã (—Ç–æ–ª—å–∫–æ –∏–º–µ–Ω–∞)
            new_processed = [os.path.basename(f) for f in processed_files]
            current_processed.extend(new_processed)

            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            current_processed = list(set(current_processed))

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            with open(self.processed_files_log, 'w') as f:
                json.dump(current_processed, f)

            print(f"üìù –õ–æ–≥ –æ–±–Ω–æ–≤–ª–µ–Ω: +{len(new_processed)} —Ñ–∞–π–ª–æ–≤, –≤—Å–µ–≥–æ {len(current_processed)}")

        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–æ–≥–∞: {e}")

    def _process_batch(self, batch_files, batch_num):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –±–∞—Ç—á —Ñ–∞–π–ª–æ–≤"""
        batch_results = []

        # 1. –û—á–∏—â–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self._cleanup_local_dirs()

        # 2. –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª—ã –±–∞—Ç—á–∞ –≤ –ª–æ–∫–∞–ª—å–Ω—É—é –§–°
        local_files = []
        print(f"üì• –°–∫–∞—á–∏–≤–∞—é {len(batch_files)} —Ñ–∞–π–ª–æ–≤ –≤ –ª–æ–∫–∞–ª—å–Ω—É—é –§–°...")

        for file_path in batch_files:
            try:
                filename = os.path.basename(file_path)
                local_path = os.path.join(self.local_batch_dir, filename)

                # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑ Drive –≤ –ª–æ–∫–∞–ª—å–Ω—É—é –§–°
                shutil.copy2(file_path, local_path)
                local_files.append(local_path)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–∫–æ–ø–∏—Ä–æ–≤–∞–ª—Å—è
                if os.path.exists(local_path):
                    size_mb = os.path.getsize(local_path) / (1024 * 1024)
                    print(f"  ‚úÖ {filename} ({size_mb:.1f} MB)")
                else:
                    print(f"  ‚ùå {filename} - –Ω–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–ª—Å—è")

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è {os.path.basename(file_path)}: {e}")

        print(f"üìä –°–∫–∞—á–∞–Ω–æ: {len(local_files)}/{len(batch_files)} —Ñ–∞–π–ª–æ–≤")

        if not local_files:
            print("‚ö†Ô∏è  –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —ç—Ç–æ–º –±–∞—Ç—á–µ")
            return []

        # 3. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
        print("\nüîä –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∞—É–¥–∏–æ...")

        for i, local_file in enumerate(local_files, 1):
            try:
                print(f"\n[{i}/{len(local_files)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {os.path.basename(local_file)}")

                # 3.1 Whisper: –ê—É–¥–∏–æ ‚Üí –¢–µ–∫—Å—Ç
                print("  üìù –®–∞–≥ 1: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç...")
                whisper_result = self._run_whisper_locally(local_file)

                if not whisper_result or 'text' not in whisper_result:
                    print("  ‚ö†Ô∏è  Whisper –Ω–µ –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç")
                    continue

                text = whisper_result['text']
                print(f"  ‚úÖ –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")

                # 3.2 LLM: –¢–µ–∫—Å—Ç ‚Üí –¢–µ–≥–∏
                print("  üè∑Ô∏è  –®–∞–≥ 2: –¢–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
                tagging_result = self._run_tagging_locally(text)

                tags = tagging_result.get('result', [])
                summary = tagging_result.get('summary', '')

                print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ —Ç–µ–≥–æ–≤: {len(tags)}")

                # 3.3 –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                result = {
                    'source_audio': os.path.basename(local_file),
                    'text': text,
                    'tags': str(tags),  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                    'summary': summary,
                    'text_length': len(text),
                    'processing_date': datetime.now().isoformat(),
                    'batch_number': batch_num,
                    'whisper_model': whisper_result.get('model', 'unknown'),
                    'audio_duration': whisper_result.get('duration', 0)
                }

                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –∏–∑ whisper_result
                if 'date' in whisper_result:
                    result['date'] = whisper_result['date']
                if 'quality_score' in whisper_result:
                    result['quality_score'] = whisper_result['quality_score']

                batch_results.append(result)

                # 3.4 –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
                os.remove(local_file)
                print(f"  üßπ –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω")

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
                import traceback
                traceback.print_exc()

        # 4. –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        self._cleanup_local_dirs()

        print(f"\n‚úÖ –ë–∞—Ç—á {batch_num} –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {len(batch_results)}/{len(batch_files)} —É—Å–ø–µ—à–Ω–æ")

        return batch_results

    def _run_whisper_locally(self, local_audio_path):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç Whisper –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞"""
        try:
            return self.ap.process_file(local_audio_path, 7, False)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Whisper: {e}")
            return {'text': '', 'error': str(e)}

    def _run_tagging_locally(self, text):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        try:
            return self.tagger.get_tags_from_llm(text)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return {'result': [], 'summary': f'–û—à–∏–±–∫–∞: {str(e)}'}

    # ========== Auxiliary methods ==========

    def _list_files_without_download(self):
        if not os.path.exists(self.drive_audio_path):
            print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.drive_audio_path}")
            return []

        audio_extensions = ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.aac', '.wma']

        all_files = []
        for ext in audio_extensions:
            pattern = f"*{ext}"
            files = list(Path(self.drive_audio_path).glob(pattern.lower()))
            files.extend(Path(self.drive_audio_path).glob(pattern.upper()))

            for file_path in files:
                if file_path.is_file():
                    all_files.append(str(file_path))

        all_files.sort()

        print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(all_files)} –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤")
        return all_files

    def _estimate_total_size_gb(self, file_paths):
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–æ–≤ –≤ GB"""
        total_bytes = 0

        for file_path in file_paths:
            try:
                total_bytes += os.path.getsize(file_path)
            except:
                total_bytes += 50 * 1024 * 1024  # 50 MB

        return total_bytes / (1024 ** 3)

    def _get_file_size_gb(self, file_path):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ GB"""
        try:
            return os.path.getsize(file_path) / (1024 ** 3)
        except:
            return 0.05  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º 50 MB

    def _create_batches(self, file_paths):
        """–°–æ–∑–¥–∞–µ—Ç –±–∞—Ç—á–∏ —Ñ–∞–π–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞"""
        batches = []
        current_batch = []
        current_batch_size = 0

        for file_path in file_paths:
            file_size_gb = self._get_file_size_gb(file_path)

            if current_batch_size + file_size_gb > self.batch_size and current_batch:
                batches.append(current_batch.copy())
                current_batch = []
                current_batch_size = 0

            current_batch.append(file_path)
            current_batch_size += file_size_gb

        if current_batch:
            batches.append(current_batch)

        optimized_batches = self._optimize_batches(batches)

        return optimized_batches

    def _optimize_batches(self, batches):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –ø–æ –±–∞—Ç—á–∞–º"""
        if len(batches) <= 1:
            return batches

        optimized = []
        current_batch = []
        current_size = 0

        for batch in batches:
            batch_size = sum(self._get_file_size_gb(f) for f in batch)

            if current_size + batch_size <= self.batch_size * 1.2:
                current_batch.extend(batch)
                current_size += batch_size
            else:
                if current_batch:
                    optimized.append(current_batch)
                current_batch = batch.copy()
                current_size = batch_size

        if current_batch:
            optimized.append(current_batch)

        print(f"üîß –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len(batches)} ‚Üí {len(optimized)} –±–∞—Ç—á–µ–π")

        return optimized

    def _cleanup_local_dirs(self):
        """–û—á–∏—â–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        for dir_path in [self.local_temp_dir, self.local_whisper_dir, self.local_batch_dir]:
            if os.path.exists(dir_path):
                for file in os.listdir(dir_path):
                    try:
                        os.remove(os.path.join(dir_path, file))
                    except:
                        pass

        print("üßπ –õ–æ–∫–∞–ª—å–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –æ—á–∏—â–µ–Ω—ã")

    def get_processing_stats(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        stats = {
            'total_files': 0,
            'processed_files': 0,
            'remaining_files': 0,
            'progress_percent': 0,
            'estimated_size_gb': 0,
            'last_processed': None
        }

        try:
            all_files = self._list_files_without_download()
            stats['total_files'] = len(all_files)
            stats['estimated_size_gb'] = self._estimate_total_size_gb(all_files)

            processed = self._load_processed_list()
            stats['processed_files'] = len(processed)
            stats['remaining_files'] = stats['total_files'] - stats['processed_files']

            if stats['total_files'] > 0:
                stats['progress_percent'] = (stats['processed_files'] / stats['total_files']) * 100

            if os.path.exists(self.output_csv_path):
                mod_time = os.path.getmtime(self.output_csv_path)
                stats['last_processed'] = datetime.fromtimestamp(mod_time).strftime("%d.%m.%Y %H:%M")

        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

        return stats


def main():
    DRIVE_AUDIO_PATH = "/content/drive/MyDrive/MCP_Call_Analytics/audio_raw"
    OUTPUT_CSV_PATH = "/content/drive/MyDrive/MCP_Call_Analytics/csv_calls/calls.csv"

    print("ü§ñ SMART AUDIO PROCESSOR - –ó–ê–ü–£–°–ö")
    print("=" * 50)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    processor = SmartAudioProcessor(
        drive_audio_path=DRIVE_AUDIO_PATH,
        output_csv_path=OUTPUT_CSV_PATH,
        total_space_gb=50,
        batch_size_gb=2
    )

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = processor.get_processing_stats()
    print(f"\n–°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–û –û–ë–†–ê–ë–û–¢–ö–ò:")
    print(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {stats['total_files']:,}")
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed_files']:,}")
    print(f"–û—Å—Ç–∞–ª–æ—Å—å: {stats['remaining_files']:,}")
    print(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {stats['progress_percent']:.1f}%")
    print(f"–û–±—â–∏–π –æ–±—ä–µ–º: {stats['estimated_size_gb']:.1f} GB")

    if stats['last_processed']:
        print(f" –ü–æ—Å–ª–µ–¥–Ω—è—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {stats['last_processed']}")

    if stats['remaining_files'] == 0:
        print("\n –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
        return

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    confirm = input(f"\n –ù–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É {stats['remaining_files']:,} —Ñ–∞–π–ª–æ–≤? (y/n): ")

    if confirm.lower() != 'y':
        print("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
        return

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    print("\n –ó–ê–ü–£–°–ö –û–ë–†–ê–ë–û–¢–ö–ò...")
    results = processor.process_large_dataset()

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if results:
        print(f"\n –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print(f" –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(results):,}")
        print(f" –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {OUTPUT_CSV_PATH}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        if os.path.exists(OUTPUT_CSV_PATH):
            df = pd.read_csv(OUTPUT_CSV_PATH)
            print(f" –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            print(" –ö–æ–ª–æ–Ω–∫–∏:", list(df.columns))
    else:
        print("\n –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")


if __name__ == "__main__":
    main()