import json
import os
import re
from typing import List, Dict, Any
import ollama  # –ò–ª–∏ openai, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ OpenAI API
from typing import Union
#from llama_cpp import Llama


class JsonFileTaggingAgent:
    def __init__(self, model, node_url=None, tags_list: List[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–≤–æ–Ω–∫–æ–≤

        Args:
            model_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Ollama
            tags_list: —Å–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        """

        self.is_local = False #isinstance(model, Llama)
        if self.is_local:
            self.model_name = 'local'
            self.model = model
        elif node_url:
            self.client = ollama.Client(host=node_url)
            self.model_name = 'from_yandex_node'
        else:
            self.client = ollama.Client()
            self.model_name = model

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–µ–≥–∏ (—Ä–∞—Å—à–∏—Ä—å—Ç–µ –ø–æ–¥ —Å–≤–æ—é –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å)
        self.tags_list = tags_list

        # –ö—ç—à –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processed_files = set()

    def process_directory(self, input_dir: str, output_dir: str = None):
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö JSON —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏

        Args:
            input_dir: –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å JSON —Ñ–∞–π–ª–∞–º–∏
            output_dir: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ None, –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–µ)
        """
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)

        json_files = [f for f in os.listdir(input_dir) if f.endswith('.json')]
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(json_files)} JSON —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        n = 0
        for i, filename in enumerate(json_files, 1):
            if filename in os.listdir(output_dir):
                n += 1
                continue
        print(f'{n} files already processed')

        for i, filename in enumerate(json_files, 1):
            print(f"\n[{i}/{len(json_files)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {filename}...")
            if filename in os.listdir(output_dir):
                continue

            input_path = os.path.join(input_dir, filename)
            output_path = os.path.join(output_dir, filename) if output_dir else input_path

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
            if filename in self.processed_files:
                print(f"   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω (—É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω)")
                continue

            try:
                result = self.tag_single_file(input_path, output_path)
                if result:
                    self.processed_files.add(filename)
                    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω. –¢–µ–≥–∏: {result.get('tags', [])}")
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")

    def tag_single_file(self, input_path: str, output_path: str) -> Dict[str, Any]:
        """
        –¢–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ JSON —Ñ–∞–π–ª–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        # –ó–∞–≥—Ä—É–∑–∫–∞ JSON
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        if 'transcription' in data and 'text' in data['transcription']:
            text = data['transcription']['text']
        elif 'text' in data:
            text = data['text']
        else:
            raise ValueError(f"–í —Ñ–∞–π–ª–µ {input_path} –Ω–µ –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –∑–≤–æ–Ω–∫–∞")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ –æ—Ç LLM
        tags_result = self.get_tags_from_llm(text)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
        if 'tags' not in data:
            data['tags'] = {}

        data['tags']['fixed_tags'] = tags_result.get('result', [])

        data.pop('segments', None)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ JSON
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        return tags_result

    def get_tags_from_llm(self, text: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ –æ—Ç LLM —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏
        """
        # –£—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ (–Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—É—Ç—å)
        truncated_text = text[:3000] + "..." if len(text) > 3000 else text

        # –°—Ç—Ä–æ–≥–∏–π –ø—Ä–æ–º–ø—Ç —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ–º JSON —Ñ–æ—Ä–º–∞—Ç–∞
        prompt = f"""–¢—ã ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤.
–ï—Å—Ç—å –∑–∞–ø–∏—Å–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã–º —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –±–µ—Ä—É—Ç –≤ –∞—Ä–µ–Ω–¥—É –∫–æ–≤—Ä—ã –∏ –ø–æ–ª—É—á–∞—é—Ç —É—Å–ª—É–≥–∏ –ø–æ –∏—Ö –¥–æ—Å—Ç–∞–≤–∫–µ (–∑–∞–º–µ–Ω–µ) –∏ —á–∏—Å—Ç–∫–µ.

–í–æ—Ç —Ç–µ–∫—Å—Ç –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:
{truncated_text}

–¢–í–û–ï –ó–ê–î–ê–ù–ò–ï: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –ø—Ä–∏—Å–≤–æ–π –µ–º—É –æ—Ç 1 –¥–æ 3 —Ç–µ–≥–æ–≤, –Ω–∞–∏–±–æ–ª–µ–µ —Ö–æ—Ä–æ—à–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É—é—â–∏—Ö –ø—Ä–∏—á–∏–Ω—ã –æ–±—Ä–∞—â–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞.
–ù–∞–ø—Ä–∏–º–µ—Ä, –∫–ª–∏–µ–Ω—Ç –¥–æ–ª–≥–æ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –µ–≥–æ –∑–∞—è–≤–∫—É –æ —Ç–æ–º, —á—Ç–æ –µ–º—É –Ω–µ –¥–æ—Å—Ç–∞–≤–∏–ª–∏ –≤–æ–≤—Ä–µ–º—è –∫–æ–≤–µ—Ä. –¢–æ–≥–¥–∞ –±—É–¥–µ—Ç –¥–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–≥–∞: –ø—Ä–æ –¥–æ–ª–≥–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∏ –ø—Ä–æ –Ω–µ–¥–æ—Å—Ç–∞–≤–∫—É (–Ω–µ—Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω—É—é –∑–∞–º–µ–Ω—É).
–õ–∏–±–æ –∫–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç –≤–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å —É—Å–ª—É–≥–∏ –ò –ø—Ä–∏ —ç—Ç–æ–º –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –∫–æ–≤—Ä–æ–≤, —á–µ–º –±—ã–ª–æ —É –Ω–µ–≥–æ —Ä–∞–Ω—å—à–µ. –¢–æ–≥–¥–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–µ–≥ –ø—Ä–æ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏ —Ç–µ–≥ –ø—Ä–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–≤—Ä–æ–≤.
–ò —Ç–∞–∫ –¥–∞–ª–µ–µ.

–¢–µ–≥–∏ –º–æ–∂–Ω–æ –±—Ä–∞—Ç—å —Å—Ç—Ä–æ–≥–æ –∏–∑ —ç—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞:
{', '.join(self.tags_list)}
–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥—Ä—É–≥–∏–µ —Ç–µ–≥–∏!

–í–ï–†–ù–ò –û–¢–í–ï–¢ –¢–û–õ–¨–ö–û –í –§–û–†–ú–ê–¢–ï JSON:
{{
  "result": ["tag1", "tag2"],
}}
–ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —è—Å–Ω–æ–π –ø—Ä–∏—á–∏–Ω—ã –æ–±—Ä–∞—â–µ–Ω–∏—è - –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤
"""

        try:
            if self.is_local:
                response = self.model(prompt,
                                      format='json',
                                      temperature=0.3,
                                      top_p=0.9)
            else:
                response = self.client.generate(
                    model=self.model_name,
                    prompt=prompt,
                    format="json",  # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞!
                    options={
                        'temperature': 0.3,  # –ú–∏–Ω–∏–º—É–º –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
                        'num_predict': 150,
                        'top_p': 0.9
                    }
                )

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            response_text = response['response']

            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–æ–±–∞–≤–∏–ª–∞ —Ç–µ–∫—Å—Ç)
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())

                # –í–∞–ª–∏–¥–∞—Ü–∏—è: –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ç–µ–≥–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–∑ –Ω–∞—à–µ–≥–æ —Å–ø–∏—Å–∫–∞
                valid_selected = []
                for tag in result.get('result', []):
                    if tag in self.tags_list:
                        valid_selected.append(tag)
                    else:
                        print(f"   ‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –ø—Ä–∏–¥—É–º–∞–ª–∞ —Ç–µ–≥ '{tag}', –∏–≥–Ω–æ—Ä–∏—Ä—É—é")

                result['result'] = valid_selected

                return result
            else:
                raise ValueError("LLM –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ JSON")

        except Exception as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LLM: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return {
                "result": [],
                "additional_tags": [],
                "reasoning": f"–û—à–∏–±–∫–∞: {str(e)}"
            }

    def validate_tags_consistency(self, input_dir: str, sample_size: int = 20):
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç—Ä–æ–ª—è)

        Args:
            input_dir: –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
            sample_size: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        """
        print("\n" + "=" * 60)
        print("üîç –ü–†–û–í–ï–†–ö–ê –ö–û–ù–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–ò –¢–ï–ì–ò–†–û–í–ê–ù–ò–Ø")
        print("=" * 60)

        json_files = [f for f in os.listdir(input_dir) if f.endswith('.json')]
        sample_files = json_files[:min(sample_size, len(json_files))]

        tag_counts = {}
        additional_counts = {}

        for filename in sample_files:
            with open(os.path.join(input_dir, filename), 'r', encoding='utf-8') as f:
                data = json.load(f)

            if 'tags' in data and 'fixed' in data['tags']:
                for tag in data['tags']['fixed']:
                    tag_counts[tag] = tag_counts.get(tag, 0) + 1

        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–ï–ì–û–í (–≤—ã–±–æ—Ä–∫–∞):")
        for tag, count in sorted(tag_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"   {tag}: {count}")

        if additional_counts:
            print("\nüí° –ü–†–ï–î–õ–û–ñ–ï–ù–ù–´–ï –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –¢–ï–ì–ò:")
            for tag, count in sorted(additional_counts.items(), key=lambda x: x[1], reverse=True):
                print(f"   '{tag}': {count}")

        print(f"\n‚úÖ –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(sample_files)}")
        print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–≥–æ–≤: {len(tag_counts)}")


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def main():
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ —Å –≤–∞—à–∏–º —Å–ø–∏—Å–∫–æ–º —Ç–µ–≥–æ–≤
    my_tags = [
        "–Ω–∏–∑–∫–æ–µ_–∫–∞—á–µ—Å—Ç–≤–æ_—Å—Ç–∏—Ä–∫–∏_–∏–ª–∏_—á–∏—Å—Ç–∫–∏",
        "–Ω–µ_–∑–∞–º–µ–Ω–∏–ª–∏_–∫–æ–≤—Ä—ã_–≤–æ–≤—Ä–µ–º—è",
        "–∫–ª–∏–µ–Ω—Ç_—Ö–æ—á–µ—Ç_–¥–æ–±–∞–≤–∏—Ç—å_–∫–æ–≤—Ä—ã",
        "–∫–ª–∏–µ–Ω—Ç_—Ö–æ—á–µ—Ç_–º–µ–Ω—å—à–µ_–∫–æ–≤—Ä–æ–≤",
        "–ø–æ–≥–∞—à–µ–Ω–∏–µ_–¥–æ–ª–≥–∞",
        "—Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ_–¥–æ–≥–æ–≤–æ—Ä–∞",
        "–≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ_—É—Å–ª—É–≥",
        "–¥–æ–ª–≥–æ_–Ω–µ—Ç_–æ—Ç–≤–µ—Ç–∞_–Ω–∞_–∑–∞—è–≤–∫—É",
        "–ª–∏—à–Ω—è—è_–¥–æ—Å—Ç–∞–≤–∫–∞",
        "–¥–æ—Å—Ç–∞–≤–∏–ª–∏_–Ω–µ_—Ç–µ_–∫–æ–≤—Ä—ã",
        "–Ω–µ_–≤—ã—Å—Ç–∞–≤–ª–µ–Ω_–≤–æ–≤—Ä–µ–º—è_—Å—á–µ—Ç",
        "–Ω–µ–≤–µ—Ä–Ω–∞—è_—Å—É–º–º–∞_–≤_—Å—á–µ—Ç–µ",
        "–∫–æ–≤–µ—Ä_–∑–∞–±—Ä–∞–ª–∏_–±–µ–∑_–ø—Ä–∏—á–∏–Ω—ã",
        "–∑–∞–±—Ä–∞–ª–∏_–Ω–µ_—Ç–æ—Ç_–∫–æ–≤–µ—Ä",
        "–º–µ–Ω–µ–¥–∂–µ—Ä_–Ω–∞–≥—Ä—É–±–∏–ª_–∫–ª–∏–µ–Ω—Ç—É",
        "–Ω–µ–æ–ø—Ä–∞–≤–¥–∞–Ω–Ω–æ_–≤—ã—Å–æ–∫–∏–µ_—Ü–µ–Ω—ã",
        "–Ω–µ–æ–ø—Ä–∞–≤–¥–∞–Ω–Ω—ã–π_—Ä–æ—Å—Ç_—Ü–µ–Ω",
        "–Ω–æ–≤—ã–π_–∫–ª–∏–µ–Ω—Ç_–∑–∞–∫–ª—é—á–µ–Ω–∏–µ_–¥–æ–≥–æ–≤–æ—Ä–∞",
        "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è_–∏–ª–∏_—É—Ç–æ—á–Ω–µ–Ω–∏–µ_–¥–µ—Ç–∞–ª–µ–π",
        "–ø–æ–º–µ–Ω—è—Ç—å_—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏",
        "–º–µ–Ω–µ–¥–∂–µ—Ä_–æ–±–µ—â–∞–ª_–Ω–æ_–Ω–µ_—Å–≤—è–∑–∞–ª—Å—è_—Å_–∫–ª–∏–µ–Ω—Ç–æ–º",
        "–∫–ª–∏–µ–Ω—Ç_—É—Ö–æ–¥–∏—Ç_–∫_–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º",
        "–ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å_—É—Å–ª—É–≥–∏",
        "–æ—à–∏–±–∫–∞_–≤_–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö"
    ]

    tagger = JsonFileTaggingAgent(
        model="mistral-nemo:12b",  # –∏–ª–∏ "mistral", "qwen2.5:7b" –∏ —Ç.–¥.
        tags_list=my_tags
    )

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    input_directory = "transcriptions/"
    output_directory = "transcriptions_with_tags_strict_deepseek/"  # –∏–ª–∏ None –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏

    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    tagger.process_directory(input_directory, output_directory)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    result_dir = output_directory or input_directory
    tagger.validate_tags_consistency(result_dir)

    print("\n" + "=" * 60)
    print("üéâ –¢–ï–ì–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 60)


if __name__ == "__main__":
    main()