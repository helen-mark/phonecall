import json
import os
import re
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import ollama
from collections import defaultdict, Counter
import sqlite3
from contextlib import contextmanager


# ==================== –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö ====================

class MetricType(Enum):
    """–¢–∏–ø—ã –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    COUNT_BY_TAG = "count_by_tag"
    TOP_N_TAGS = "top_n_tags"
    TAG_TRENDS = "tag_trends"
    COMPARISON = "comparison"
    SUMMARY_STATS = "summary_stats"


@dataclass
class AnalysisPlan:
    """–ü–ª–∞–Ω –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç LLM"""
    time_period: Dict[str, Any]  # start, end, description
    target_tags: List[str]
    metrics: List[MetricType]
    grouping: str = "month"
    comparison_tags: List[str] = None
    additional_filters: Dict = None

    def to_dict(self):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è JSON"""
        return {
            'time_period': self.time_period,
            'target_tags': self.target_tags,
            'metrics': [m.value for m in self.metrics],
            'grouping': self.grouping,
            'comparison_tags': self.comparison_tags,
            'filters': self.additional_filters or {}
        }


# ==================== JSON Data Loader ====================

class JSONDataLoader:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ JSON —Ñ–∞–π–ª–æ–≤"""

    def __init__(self, json_directory: str):
        self.json_dir = json_directory
        self.calls_cache = None
        self.conn = None  # In-memory SQLite —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ

    def load_all_calls(self, limit: int = None) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –∑–≤–æ–Ω–∫–∏ –∏–∑ JSON —Ñ–∞–π–ª–æ–≤"""
        if self.calls_cache is not None:
            return self.calls_cache[:limit] if limit else self.calls_cache

        all_calls = []
        files_processed = 0

        for filename in sorted(os.listdir(self.json_dir)):
            if not filename.endswith('.json'):
                continue

            filepath = os.path.join(self.json_dir, filename)

            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                call_date = self._extract_date_from_filename(filename)

                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
                call_record = {
                    'id': f"call_{files_processed}",
                    'file_name': filename,
                    'call_date': call_date,
                    'year': call_date.year,
                    'month': call_date.month,
                    'day': call_date.day,
                    'full_text': data.get('text', ''),
                    'summary': data.get('reason', ''),
                    'tags': data.get('tags').get('fixed_tags', []),
                    'text_length': len(data.get('text', '')),
                    'source_file': filepath
                }

                all_calls.append(call_record)
                files_processed += 1

                if limit and files_processed >= limit:
                    break

            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filename}: {e}")

        self.calls_cache = all_calls
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_calls)} –∑–≤–æ–Ω–∫–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–æ–≤")
        return all_calls

    def _extract_date_from_filename(self, filename: str) -> datetime:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–∞—Ç—ã –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        patterns = [
            r'(\d{4})-(\d{2})-(\d{2})',  # YYYY-MM-DD
            # r'(\d{2})\.(\d{2})\.(\d{4})',  # DD.MM.YYYY
            # r'(\d{4})(\d{2})(\d{2})',  # YYYYMMDD
        ]

        for pattern in patterns:
            match = re.search(pattern, filename)
            if match:
                groups = match.groups()
                if len(groups) == 3:
                    if pattern == patterns[0]:  # YYYY-MM-DD
                        year, month, day = map(int, groups)
                        return datetime(year, month, day)
                    elif pattern == patterns[1]:  # DD.MM.YYYY
                        day, month, year = map(int, groups)
                        return datetime(year, month, day)
                    elif pattern == patterns[2]:  # YYYYMMDD
                        year, month, day = int(groups[0]), int(groups[1]), int(groups[2])
                        return datetime(year, month, day)

        # –ï—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞—Ç—É –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
        filepath = os.path.join(self.json_dir, filename)
        if os.path.exists(filepath):
            return datetime.fromtimestamp(os.path.getmtime(filepath))

        # Fallback: —Ç–µ–∫—É—â–∞—è –¥–∞—Ç–∞
        return datetime.now()

    def setup_in_memory_db(self):
        """–°–æ–∑–¥–∞–µ—Ç in-memory SQLite –±–∞–∑—É –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if self.conn is not None:
            return self.conn

        self.conn = sqlite3.connect(':memory:')
        cursor = self.conn.cursor()

        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
        cursor.execute("""
        CREATE TABLE calls (
            id TEXT PRIMARY KEY,
            file_name TEXT,
            call_date TEXT,
            year INTEGER,
            month INTEGER,
            day INTEGER,
            full_text TEXT,
            summary TEXT,
            tags_json TEXT,
            text_length INTEGER
        )
        """)

        cursor.execute("""
        CREATE TABLE call_tags (
            call_id TEXT,
            tag TEXT,
            FOREIGN KEY (call_id) REFERENCES calls(id)
        )
        """)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        calls = self.load_all_calls()
        for call in calls:
            cursor.execute("""
            INSERT INTO calls (id, file_name, call_date, year, month, day, 
                              full_text, summary, tags_json, text_length)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                call['id'],
                call['file_name'],
                call['call_date'].isoformat(),
                call['year'],
                call['month'],
                call['day'],
                call['full_text'],
                call['summary'],
                json.dumps(call['tags'], ensure_ascii=False),
                call['text_length']
            ))

            # –í—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–≥–∏
            for tag in call['tags']:
                cursor.execute(
                    "INSERT INTO call_tags (call_id, tag) VALUES (?, ?)",
                    (call['id'], tag)
                )

        self.conn.commit()
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ in-memory SQLite ({len(calls)} –∑–∞–ø–∏—Å–µ–π)")
        return self.conn

    @contextmanager
    def get_cursor(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∫—É—Ä—Å–æ—Ä–∞"""
        if self.conn is None:
            self.setup_in_memory_db()

        cursor = self.conn.cursor()
        try:
            yield cursor
        finally:
            cursor.close()


# ==================== DeepSeek Planner ====================

class DeepSeekPlanner:
    """LLM –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤"""

    def __init__(self, model_name):
        self.client = ollama.Client()
        self.model_name = model_name
        self.available_tags = self._load_available_tags()

    def _load_available_tags(self) -> List[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏ –∏–∑ JSON —Ñ–∞–π–ª–æ–≤ (–¥–ª—è –ø—Ä–∏–º–µ—Ä–∞)"""
        # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –¥–∞–Ω–Ω—ã—Ö
        return [
            "–Ω–∏–∑–∫–æ–µ_–∫–∞—á–µ—Å—Ç–≤–æ_—Å—Ç–∏—Ä–∫–∏_–∏–ª–∏_—á–∏—Å—Ç–∫–∏",
            "–Ω–µ_–∑–∞–º–µ–Ω–∏–ª–∏_–∫–æ–≤—Ä—ã_–≤–æ–≤—Ä–µ–º—è",
            "–∫–ª–∏–µ–Ω—Ç_—Ö–æ—á–µ—Ç_–¥–æ–±–∞–≤–∏—Ç—å_–∫–æ–≤—Ä—ã",
            "–∫–ª–∏–µ–Ω—Ç_—Ö–æ—á–µ—Ç_–º–µ–Ω—å—à–µ_–∫–æ–≤—Ä–æ–≤",
            "–ø–æ–≥–∞—à–µ–Ω–∏–µ_–¥–æ–ª–≥–∞",
            "—Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ_–¥–æ–≥–æ–≤–æ—Ä–∞",
            "–≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ_—É—Å–ª—É–≥",
            "–¥–æ–ª–≥–æ_–Ω–µ—Ç_–æ—Ç–≤–µ—Ç–∞_–Ω–∞_–∑–∞—è–≤–∫—É",
            "–ª–∏—à–Ω—è—è_–¥–æ—Å—Ç–∞–≤–∫–∞",
            "–¥–æ—Å—Ç–∞–≤–∏–ª–∏_–Ω–µ_—Ç–µ_–∫–æ–≤—Ä—ã",
            "–Ω–µ_–≤—ã—Å—Ç–∞–≤–ª–µ–Ω_–≤–æ–≤—Ä–µ–º—è_—Å—á–µ—Ç",
            "–Ω–µ–≤–µ—Ä–Ω–∞—è_—Å—É–º–º–∞_–≤_—Å—á–µ—Ç–µ",
            "–∫–æ–≤–µ—Ä_–∑–∞–±—Ä–∞–ª–∏_–±–µ–∑_–ø—Ä–∏—á–∏–Ω—ã",
            "–∑–∞–±—Ä–∞–ª–∏_–Ω–µ_—Ç–æ—Ç_–∫–æ–≤–µ—Ä",
            "–º–µ–Ω–µ–¥–∂–µ—Ä_–Ω–∞–≥—Ä—É–±–∏–ª_–∫–ª–∏–µ–Ω—Ç—É",
            "–Ω–µ–æ–ø—Ä–∞–≤–¥–∞–Ω–Ω–æ_–≤—ã—Å–æ–∫–∏–µ_—Ü–µ–Ω—ã",
            "–Ω–µ–æ–ø—Ä–∞–≤–¥–∞–Ω–Ω—ã–π_—Ä–æ—Å—Ç_—Ü–µ–Ω",
            "–Ω–æ–≤—ã–π_–∫–ª–∏–µ–Ω—Ç_–∑–∞–∫–ª—é—á–µ–Ω–∏–µ_–¥–æ–≥–æ–≤–æ—Ä–∞",
            "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è_–∏–ª–∏_—É—Ç–æ—á–Ω–µ–Ω–∏–µ_–¥–µ—Ç–∞–ª–µ–π",
            "–ø–æ–º–µ–Ω—è—Ç—å_—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏",
            "–º–µ–Ω–µ–¥–∂–µ—Ä_–æ–±–µ—â–∞–ª_–Ω–æ_–Ω–µ_—Å–≤—è–∑–∞–ª—Å—è_—Å_–∫–ª–∏–µ–Ω—Ç–æ–º",
            "–∫–ª–∏–µ–Ω—Ç_—É—Ö–æ–¥–∏—Ç_–∫_–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º",
            "–ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å_—É—Å–ª—É–≥–∏",
            "–æ—à–∏–±–∫–∞_–≤_–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö"
        ]

    def create_analysis_plan(self, user_query: str) -> AnalysisPlan:
        """–°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

        prompt = self._build_planner_prompt(user_query)

        try:
            response = self.client.generate(
                model=self.model_name,
                prompt=prompt,
                format="json",
                options={'temperature': 0.1, 'num_predict': 500}
            )

            plan_data = json.loads(response['response'])

            # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–µ—Ä–∏–æ–¥
            time_period = self._parse_time_period(plan_data.get('time_period', {}))

            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–µ–≥–∏
            target_tags = self._validate_tags(plan_data.get('target_tags', []))

            # –ü–∞—Ä—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏
            metrics = self._parse_metrics(plan_data.get('metrics', []))

            return AnalysisPlan(
                time_period=time_period,
                target_tags=target_tags,
                metrics=metrics,
                grouping=plan_data.get('grouping', 'month'),
                comparison_tags=plan_data.get('comparison_tags', []),
                additional_filters=plan_data.get('filters', {})
            )

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–ª–∞–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            return self._create_default_plan(user_query)

    def _build_planner_prompt(self, user_query: str) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
        current_date = datetime.now().strftime("%Y-%m-%d")
        print('Current date:', current_date)

        return f"""–¢—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫ –±–∞–∑—ã —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ –∞—Ä–µ–Ω–¥–µ —à—Ç–æ—Ä.

–ó–ê–ü–†–û–°: "{user_query}"

–¢–í–û–Ø –ó–ê–î–ê–ß–ê: –°–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω –∞–Ω–∞–ª–∏–∑–∞.
–°–∏—Å—Ç–µ–º–∞ –±—É–¥–µ—Ç –æ–±—Ä–∞—â–∞—Ç—å—Å—è –ø–æ —Ç–≤–æ–µ–º—É –ø–ª–∞–Ω—É –∫ —Ç–µ–∫—Å—Ç–∞–º —Å –∑–∞–ø–∏—Å—è–º–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤ –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ª–µ—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º–∏ –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Ç–µ–≥–∏ –∫–∞–∂–¥–æ–≥–æ –∑–≤–æ–Ω–∫–∞.

–î–û–°–¢–£–ü–ù–´–ï –¢–ï–ì–ò:
{', '.join(self.available_tags)}

–ú–ï–¢–†–ò–ö–ò, –∫–æ—Ç–æ—Ä—ã–µ —Å–∏—Å—Ç–µ–º–∞ –º–æ–∂–µ—Ç –ø–æ—Å—á–∏—Ç–∞—Ç—å –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ:
1. count_by_tag - –ø–æ–¥—Å—á–µ—Ç –∑–≤–æ–Ω–∫–æ–≤ —Å –∑–∞–¥–∞–Ω–Ω—ã–º —Ç–µ–≥–æ–º –∑–∞ –ø–µ—Ä–∏–æ–¥
2. top_n_tags - —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —Ç–µ–≥–∏ –∑–≤–æ–Ω–∫–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥
3. tag_trends - –¥–∏–Ω–∞–º–∏–∫–∞ —Ç–µ–≥–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏: —Å—Ç–∞–ª –ª–∏ —á–∞—â–µ –∏–ª–∏ —Ä–µ–∂–µ –≤—Å—Ç—Ä–µ—á–∞—Ç—å—Å—è –∑–∞ –ø–µ—Ä–∏–æ–¥?
–°–µ–≥–æ–¥–Ω—è—à–Ω—è—è –¥–∞—Ç–∞: {current_date} - –∏—Å–ø–æ–ª—å–∑—É–π –µ–µ, —á—Ç–æ–±—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–µ—Ä–∏–æ–¥ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–µ—Ä–∏–æ–¥ —É–∫–∞–∑–∞–Ω –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–≤ –ø—Ä–æ—à–ª–æ–º –≥–æ–¥—É" –∏ —Ç.–ø.)

–í–ï–†–ù–ò JSON —Å –ø–ª–∞–Ω–æ–º —Ç–æ–≥–æ, —á—Ç–æ —Å–∏—Å—Ç–µ–º–µ –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –∏–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å, –∞ –∏–º–µ–Ω–Ω–æ: –∑–∞ –∫–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥ –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è –¥–∞–Ω–Ω—ã–µ? –ü–æ –∫–∞–∫–∏–º –∏–º–µ–Ω–æ —Ç–µ–≥–∞–º –≤—ã–±–∏—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –¥–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å? –ö–∞–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–¥—Å—á–∏—Ç–∞—Ç—å –ø–æ —ç—Ç–∏–º –¥–∞–Ω–Ω—ã–º –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –¥–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å?
{{
  "time_period": {{
    "description": "–æ–ø–∏—Å–∞–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–∞",
    "start": "YYYY-MM-DD –∏–ª–∏ null",
    "end": "YYYY-MM-DD –∏–ª–∏ null"
  }},
  "target_tags": ["—Ç–µ–≥1", "—Ç–µ–≥2", ... (1 or more tags)],
  "metrics": ["count_by_tag" and/or "tag_trends" and/or "top_n_tags" (necessary metrics)],
  "grouping": "month/week/day"
  }}

–û—Ç–≤–µ—Ç:"""

    def _parse_time_period(self, period_data: Dict) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–µ—Ä–∏–æ–¥"""
        today = datetime.now()
        description = period_data.get('description', '')

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏—è
        # if '–ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 –º–µ—Å—è—Ü–µ–≤' in description.lower():
        #     start = today - timedelta(days=30 * 6)
        #     end = today
        # elif '—ç—Ç–æ—Ç –º–µ—Å—è—Ü' in description.lower():
        #     start = datetime(today.year, today.month, 1)
        #     end = today
        # elif '—ç—Ç–æ—Ç –≥–æ–¥' in description.lower():
        #     start = datetime(today.year, 1, 1)
        #     end = today
        # elif '–ø–µ—Ä–≤—ã–π –∫–≤–∞—Ä—Ç–∞–ª 2024' in description.lower():
        #     start = datetime(2024, 1, 1)
        #     end = datetime(2024, 3, 31)
        # else:
        #     # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü
        #     start = today - timedelta(days=30)
        #     end = today

        # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã —Ç–æ—á–Ω—ã–µ –¥–∞—Ç—ã
        if period_data.get('start'):
            start = datetime.fromisoformat(period_data['start'])
        if period_data.get('end'):
            end = datetime.fromisoformat(period_data['end'])

        return {
            'start': start,
            'end': end,
            'description': description or f"—Å {start.strftime('%d.%m.%Y')} –ø–æ {end.strftime('%d.%m.%Y')}"
        }

    def _validate_tags(self, tags: List[str]) -> List[str]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–≥–∏"""
        valid_tags = []
        for tag in tags:
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ–≥–∏
            for available_tag in self.available_tags:
                if tag.lower() in available_tag.lower() or available_tag.lower() in tag.lower():
                    valid_tags.append(available_tag)
                    break

        return valid_tags or ['–∂–∞–ª–æ–±–∞_–∫–∞—á–µ—Å—Ç–≤–æ_—Å—Ç–∏—Ä–∫–∏']  # Fallback

    def _parse_metrics(self, metrics: List[str]) -> List[MetricType]:
        """–ü–∞—Ä—Å–∏—Ç –º–µ—Ç—Ä–∏–∫–∏"""
        metric_map = {
            'count_by_tag': MetricType.COUNT_BY_TAG,
            'top_n_tags': MetricType.TOP_N_TAGS,
            'tag_trends': MetricType.TAG_TRENDS,
            'comparison': MetricType.COMPARISON
        }

        result = []
        for metric in metrics:
            if metric in metric_map:
                result.append(metric_map[metric])

        return result or [MetricType.COUNT_BY_TAG]

    def _create_default_plan(self, user_query: str) -> AnalysisPlan:
        """–°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        today = datetime.now()

        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–≥–∞
        target_tags = []
        if '–∫–∞—á–µ—Å—Ç–≤' in user_query.lower():
            target_tags.append('–∂–∞–ª–æ–±–∞_–∫–∞—á–µ—Å—Ç–≤–æ_—Å—Ç–∏—Ä–∫–∏')
        if '–¥–æ—Å—Ç–∞–≤–∫' in user_query.lower():
            target_tags.append('–∂–∞–ª–æ–±–∞_–¥–æ–ª–≥–∞—è_–¥–æ—Å—Ç–∞–≤–∫–∞')

        return AnalysisPlan(
            time_period={
                'start': today - timedelta(days=30 * 6),
                'end': today,
                'description': '–ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 –º–µ—Å—è—Ü–µ–≤'
            },
            target_tags=target_tags or ['–∂–∞–ª–æ–±–∞_–∫–∞—á–µ—Å—Ç–≤–æ_—Å—Ç–∏—Ä–∫–∏'],
            metrics=[MetricType.COUNT_BY_TAG, MetricType.TAG_TRENDS],
            grouping='month'
        )


# ==================== Query Executor ====================

class JSONQueryExecutor:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –∫ JSON –¥–∞–Ω–Ω—ã–º"""

    def __init__(self, data_loader: JSONDataLoader):
        self.data_loader = data_loader

    def execute_plan(self, plan: AnalysisPlan) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–ª–∞–Ω –∞–Ω–∞–ª–∏–∑–∞"""

        results = {}

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–µ—Ä–∏–æ–¥
        all_calls = self.data_loader.load_all_calls()
        print(f'{len(all_calls)} calls in total')
        print(all_calls[:2])
        filtered_calls = self._filter_calls_by_period(all_calls, plan.time_period)
        print(f'{len(filtered_calls)} calls after filtering')

        # –í—ã–ø–æ–ª–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        for metric in plan.metrics:
            if metric == MetricType.COUNT_BY_TAG:
                results['count_by_tag'] = self._count_by_tag(filtered_calls, plan.target_tags)

            elif metric == MetricType.TAG_TRENDS:
                results['tag_trends'] = self._tag_trends(
                    filtered_calls,
                    plan.target_tags,
                    plan.grouping
                )

            elif metric == MetricType.TOP_N_TAGS:
                results['top_n_tags'] = self._top_n_tags(filtered_calls, n=5)

            elif metric == MetricType.COMPARISON:
                results['comparison'] = self._compare_tags(
                    filtered_calls,
                    plan.comparison_tags or plan.target_tags[:2]
                )

            print(f'executions result: {results}')

        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        results['summary_stats'] = {
            'total_calls': len(filtered_calls),
            'period': plan.time_period['description'],
            'date_range': f"{plan.time_period['start'].strftime('%Y-%m-%d')} - {plan.time_period['end'].strftime('%Y-%m-%d')}"
        }

        return results

    def _filter_calls_by_period(self, calls: List[Dict], period: Dict) -> List[Dict]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –∑–≤–æ–Ω–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É –ø–µ—Ä–∏–æ–¥—É"""
        start_date = period['start']
        end_date = period['end']

        filtered = []
        for call in calls:
            call_date = call['call_date']
            if start_date <= call_date <= end_date:
                filtered.append(call)

        return filtered

    def _count_by_tag(self, calls: List[Dict], target_tags: List[str]) -> Dict[str, int]:
        """–ü–æ–¥—Å—á–µ—Ç –∑–≤–æ–Ω–∫–æ–≤ –ø–æ —Ç–µ–≥–∞–º"""
        counts = defaultdict(int)

        for call in calls:
            for tag in call['tags']:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ —Ç–µ–≥ —Å —Ü–µ–ª–µ–≤—ã–º–∏
                for target in target_tags:
                    if target.lower() in tag.lower() or tag.lower() in target.lower():
                        counts[target] += 1
                        break

        return dict(counts)

    def _tag_trends(self, calls: List[Dict], target_tags: List[str], grouping: str) -> Dict[str, List]:
        """–î–∏–Ω–∞–º–∏–∫–∞ —Ç–µ–≥–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏"""
        if not target_tags:
            return {}

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–µ—Å—è—Ü–∞–º/–Ω–µ–¥–µ–ª—è–º
        trends = defaultdict(lambda: defaultdict(int))

        for call in calls:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
            if grouping == 'month':
                period_key = call['call_date'].strftime('%Y-%m')
            elif grouping == 'week':
                year, week, _ = call['call_date'].isocalendar()
                period_key = f"{year}-W{week:02d}"
            else:  # day
                period_key = call['call_date'].strftime('%Y-%m-%d')

            # –°—á–∏—Ç–∞–µ–º —Ç–µ–≥–∏
            for tag in call['tags']:
                for target in target_tags:
                    if target.lower() in tag.lower() or tag.lower() in target.lower():
                        trends[target][period_key] += 1
                        break

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–≥–∞
        result = {}
        for tag, period_counts in trends.items():
            result[tag] = [
                {'period': period, 'count': count}
                for period, count in sorted(period_counts.items())
            ]

        return result

    def _top_n_tags(self, calls: List[Dict], n: int = 5) -> List[Dict]:
        """–¢–æ–ø-N —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Ç–µ–≥–æ–≤"""
        tag_counter = Counter()

        for call in calls:
            tag_counter.update(call['tags'])

        return [
            {'tag': tag, 'count': count}
            for tag, count in tag_counter.most_common(n)
        ]

    def _compare_tags(self, calls: List[Dict], tags: List[str]) -> Dict[str, Any]:
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –¥–≤–∞ —Ç–µ–≥–∞"""
        if len(tags) < 2:
            tags = tags + [None] * (2 - len(tags))

        counts = self._count_by_tag(calls, tags[:2])

        return {
            'tag1': {'name': tags[0], 'count': counts.get(tags[0], 0)},
            'tag2': {'name': tags[1], 'count': counts.get(tags[1], 0)},
            'total_calls': len(calls),
            'ratio': counts.get(tags[0], 0) / counts.get(tags[1], 1) if counts.get(tags[1], 0) > 0 else 0
        }


# ==================== DeepSeek Analyzer ====================

class DeepSeekAnalyzer:
    """LLM –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤"""

    def __init__(self, model_name: str):
        self.client = ollama.Client()
        self.model_name = model_name

    def generate_answer(self, user_query: str, results: Dict, plan: AnalysisPlan) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

        prompt = self._build_analyzer_prompt(user_query, results, plan)

        try:
            response = self.client.generate(
                model=self.model_name,
                prompt=prompt,
                options={'temperature': 0.3, 'num_predict': 800}
            )

            return response['response'].strip()

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞: {e}")
            return self._generate_fallback_answer(results, plan)

    def _build_analyzer_prompt(self, user_query: str, results: Dict, plan: AnalysisPlan) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        results_str = json.dumps(results, ensure_ascii=False, indent=2, default=str)
        print(f'Generating answer using plan results: {results} for plan: {plan}')
        print(f'User query: {user_query}')

        return f"""–¢—ã ‚Äî —Å—Ç–∞—Ä—à–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ –∞—Ä–µ–Ω–¥–µ –∫–æ–≤—Ä–æ–≤.

–ó–ê–ü–†–û–° –ö–õ–ò–ï–ù–¢–ê: "{user_query}"

–î–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å —Å–∏—Å—Ç–µ–º–∞ –≤—ã–±—Ä–∞–ª–∞ —Ç–µ–∫—Å—Ç—ã –æ–±—Ä–∞—â–µ–Ω–∏–π –∫–ª–∏–µ–Ω—Ç–æ–≤ –∑–∞ –Ω—É–∂–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –∏ –ø–æ—Å—á–∏—Ç–∞–ª–∞ –Ω—É–∂–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏.
- –ü–µ—Ä–∏–æ–¥, –∫–æ—Ç–æ—Ä—ã–º –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–ª—Å—è –∫–ª–∏–µ–Ω—Ç: {plan.time_period['description']}
- –ü–æ–¥—Ö–æ–¥—è—â–∏–µ —Ç–µ–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–±—Ä–∞–ª–∞ —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–±—Ä–∞—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {', '.join(plan.target_tags)}
- –ú–µ—Ç—Ä–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–∏—Å—Ç–µ–º–∞ –ø–æ–¥—Å—á–∏—Ç–∞–ª–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞, –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤ –æ–±—Ä–∞—â–µ–Ω–∏–π, –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ —ç—Ç–∏–º —Ç–µ–≥–∞–º: {[m.value for m in plan.metrics]}

–í–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–¥–∞–ª–∞ —Å–∏—Å—Ç–µ–º–∞ –ø–æ –ø–æ–¥—Å—á–µ—Ç–∞–º –º–µ—Ç—Ä–∏–∫ –¥–ª—è —ç—Ç–∏—Ö —Ç–µ–≥–æ–≤:
{results_str}

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ü–∏—Ñ—Ä—ã –≤ —ç—Ç–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö (–µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –ø—É—Å—Ç–æ–π!)
2. –û—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞
3. –í—ã–¥–µ–ª–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã
4. –ì–æ–≤–æ—Ä–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, —Å —Ü–∏—Ñ—Ä–∞–º–∏

–§–û–†–ú–ê–¢:
- –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥
- –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)

–ï—Å–ª–∏ —Ç—ã –≤–∏–¥–∏—à—å, —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –¥–∞–ª–∞ —Ç–µ–±–µ –ø—É—Å—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏, –∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –Ω–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞, - —Ç–∞–∫ –∏ –Ω–∞–ø–∏—à–∏.

–û–¢–í–ï–¢ –ù–ê –†–£–°–°–ö–û–ú:"""

    def _generate_fallback_answer(self, results: Dict, plan: AnalysisPlan) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –µ—Å–ª–∏ LLM –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞"""

        answer_parts = []

        # –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥
        answer_parts.append(f"üìä –ê–Ω–∞–ª–∏–∑ –∑–∞ –ø–µ—Ä–∏–æ–¥: {plan.time_period['description']}")

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ —Ç–µ–≥–∞–º
        if 'count_by_tag' in results:
            answer_parts.append("\nüìà –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–≤–æ–Ω–∫–æ–≤ –ø–æ —Ç–µ–≥–∞–º:")
            for tag, count in results['count_by_tag'].items():
                answer_parts.append(f"  ‚Ä¢ {tag}: {count}")

        # –î–∏–Ω–∞–º–∏–∫–∞
        if 'tag_trends' in results:
            for tag, trends in results['tag_trends'].items():
                if trends:
                    first = trends[0]['count']
                    last = trends[-1]['count']
                    change = ((last - first) / first * 100) if first > 0 else 0
                    trend_desc = "üìà —Ä–æ—Å—Ç" if change > 0 else "üìâ —Å–Ω–∏–∂–µ–Ω–∏–µ" if change < 0 else "‚û°Ô∏è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π"
                    answer_parts.append(f"\nüìÖ –î–∏–Ω–∞–º–∏–∫–∞ '{tag}': {trend_desc} ({abs(change):.1f}%)")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if 'count_by_tag' in results:
            max_tag = max(results['count_by_tag'].items(), key=lambda x: x[1])[0] if results['count_by_tag'] else None
            if max_tag and '–∂–∞–ª–æ–±–∞' in max_tag:
                answer_parts.append(
                    f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–µ–≥ '{max_tag}' - —ç—Ç–æ —Å–∞–º–∞—è —á–∞—Å—Ç–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –æ–±—Ä–∞—â–µ–Ω–∏–π")

        return "\n".join(answer_parts)


# ==================== –ì–ª–∞–≤–Ω–∞—è MCP —Å–∏—Å—Ç–µ–º–∞ ====================

class JSONCallAnalyticsMCP:
    """–ì–ª–∞–≤–Ω–∞—è MCP —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å JSON —Ñ–∞–π–ª–∞–º–∏"""

    def __init__(self, json_directory: str, model_name: str):
        self.data_loader = JSONDataLoader(json_directory)
        self.planner = DeepSeekPlanner(model_name)
        self.executor = JSONQueryExecutor(self.data_loader)
        self.analyzer = DeepSeekAnalyzer(model_name)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        print("üìÇ –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–æ–≤...")
        self.total_calls = len(self.data_loader.load_all_calls())
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {self.total_calls} –∑–≤–æ–Ω–∫–æ–≤")

    def process_query(self, user_query: str) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

        print(f"\nüîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–ø—Ä–æ—Å: '{user_query}'")

        # 1. –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (LLM)
        print("ü§ñ –°–æ–∑–¥–∞—é –ø–ª–∞–Ω –∞–Ω–∞–ª–∏–∑–∞...")
        analysis_plan = self.planner.create_analysis_plan(user_query)

        print(f"   üìÖ –ü–µ—Ä–∏–æ–¥: {analysis_plan.time_period['description'], analysis_plan.time_period['start'], analysis_plan.time_period['end']}")
        print(f"   üè∑Ô∏è  –¢–µ–≥–∏: {', '.join(analysis_plan.target_tags)}")
        print(f"   üìä –ú–µ—Ç—Ä–∏–∫–∏: {[m.value for m in analysis_plan.metrics]}")

        # 2. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
        print("üìä –í—ã–ø–æ–ª–Ω—è—é –∞–Ω–∞–ª–∏–∑...")
        analysis_results = self.executor.execute_plan(analysis_plan)

        # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ (LLM)
        print("üí≠ –§–æ—Ä–º—É–ª–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")
        answer = self.analyzer.generate_answer(user_query, analysis_results, analysis_plan)

        # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
        response = {
            'query': user_query,
            'analysis_plan': analysis_plan.to_dict(),
            'raw_results': analysis_results,
            'answer': answer,
            'total_calls_analyzed': analysis_results.get('summary_stats', {}).get('total_calls', 0),
            'processing_time': datetime.now().isoformat(),
            'model_used': self.planner.model_name
        }

        # 5. –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._print_analysis_summary(analysis_results)

        return response

    def _print_analysis_summary(self, results: Dict[str, Any]):
        """–í—ã–≤–æ–¥–∏—Ç –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞"""
        print("üìà –ö–†–ê–¢–ö–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print("-" * 40)

        if 'summary_stats' in results:
            stats = results['summary_stats']
            print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {stats.get('period', 'N/A')}")
            print(f"üìû –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∑–≤–æ–Ω–∫–æ–≤: {stats.get('total_calls', 0)}")

        if 'count_by_tag' in results:
            counts = results['count_by_tag']
            if counts:
                print("\nüìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ —Ç–µ–≥–∞–º:")
                for tag, count in counts.items():
                    print(f"  ‚Ä¢ {tag}: {count}")

        if 'top_n_tags' in results:
            print("\nüèÜ –¢–æ–ø —Ç–µ–≥–∏:")
            for i, item in enumerate(results['top_n_tags'][:3], 1):
                print(f"  {i}. {item['tag']}: {item['count']}")

        if 'tag_trends' in results:
            for tag, trends in results['tag_trends'].items():
                if trends and len(trends) >= 2:
                    first = trends[0]['count']
                    last = trends[-1]['count']
                    change = ((last - first) / first * 100) if first > 0 else 0
                    trend_icon = "üìà" if change > 0 else "üìâ" if change < 0 else "‚û°Ô∏è"
                    print(f"\nüìÖ –î–∏–Ω–∞–º–∏–∫–∞ '{tag}': {trend_icon} {abs(change):.1f}%")

        print("-" * 40)

    def get_system_info(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ"""
        calls = self.data_loader.load_all_calls()

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–≥–∏
        all_tags = []
        for call in calls:
            all_tags.extend(call['tags'])

        unique_tags = set(all_tags)

        # –î–∞—Ç—ã
        dates = [call['call_date'] for call in calls]

        return {
            'total_calls': len(calls),
            'unique_tags_count': len(unique_tags),
            'date_range': {
                'start': min(dates).isoformat() if dates else None,
                'end': max(dates).isoformat() if dates else None
            },
            'average_text_length': sum(len(c['full_text']) for c in calls) // len(calls) if calls else 0,
            'model': self.planner.model_name,
            'data_source': 'JSON files'
        }

    def test_system(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É—é —Å–∏—Å—Ç–µ–º—É...")

        try:
            # –¢–µ—Å—Ç 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            calls = self.data_loader.load_all_calls(limit=10)
            if not calls:
                print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
                return False

            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(calls)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")

            # –¢–µ—Å—Ç 2: –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
            test_query = "–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: –∂–∞–ª–æ–±—ã –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ"
            plan = self.planner.create_analysis_plan(test_query)
            if not plan.target_tags:
                print("‚ùå –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –Ω–µ –≤–µ—Ä–Ω—É–ª —Ç–µ–≥–∏")
                return False

            print(f"‚úÖ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç, –≤—ã–±—Ä–∞–Ω—ã —Ç–µ–≥–∏: {plan.target_tags}")

            # –¢–µ—Å—Ç 3: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            results = self.executor.execute_plan(plan)
            if 'summary_stats' not in results:
                print("‚ùå –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                return False

            print(f"‚úÖ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª {results['summary_stats'].get('total_calls', 0)} –∑–≤–æ–Ω–∫–æ–≤")

            # –¢–µ—Å—Ç 4: –ê–Ω–∞–ª–∏–∑
            answer = self.analyzer.generate_answer(test_query, results, plan)
            if not answer or len(answer) < 10:
                print("‚ùå –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –æ—Ç–≤–µ—Ç")
                return False

            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {len(answer)} —Å–∏–º–≤–æ–ª–æ–≤")

            print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
            import traceback
            traceback.print_exc()
            return False